{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mogaveera/atmanomalydetection/blob/master/ImageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IEUHwiPyVjR",
        "colab_type": "code",
        "outputId": "563f01d6-2130-4cf2-b8f9-7e2a50fd8e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRIH382JxkHQ",
        "colab_type": "code",
        "outputId": "465d7c12-4e8a-49bd-da5a-a5f6e4a4db94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/mf1024/ImageNet-datasets-downloader"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ImageNet-datasets-downloader'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 113 (delta 64), reused 35 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (113/113), 1.57 MiB | 1.76 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGTZptbSxnJO",
        "colab_type": "code",
        "outputId": "f8824f9e-ccab-4b9e-c50a-a2dcc6372a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./ImageNet-datasets-downloader/downloader.py \\\n",
        "    -data_root ./images \\\n",
        "    -use_class_list True \\\n",
        "    -class_list n07942152 n03343560 n03085602 n02958343 n00446493 n02799175 n03148324\\\n",
        "    -images_per_class 1000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Picked the following clases:\n",
            "['people', 'fire', 'computer screen', 'car', 'fight', 'baseball bat', 'cupboard']\n",
            "Scraping images for class \"people\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 242.0 urls with 178.0 successes\n",
            "73.55371900826447% success rate for is_flickr urls \n",
            "0.04189421085829146 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 242.0 urls with 178.0 successes\n",
            "73.55371900826447% success rate for all urls \n",
            "0.04189452964268374 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 492.0 urls with 362.0 successes\n",
            "73.57723577235772% success rate for is_flickr urls \n",
            "0.03756466162138881 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 492.0 urls with 362.0 successes\n",
            "73.57723577235772% success rate for all urls \n",
            "0.037564975780676746 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 742.0 urls with 544.0 successes\n",
            "73.31536388140162% success rate for is_flickr urls \n",
            "0.037549308555967664 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 742.0 urls with 544.0 successes\n",
            "73.31536388140162% success rate for all urls \n",
            "0.03754940146909041 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 992.0 urls with 731.0 successes\n",
            "73.68951612903226% success rate for is_flickr urls \n",
            "0.03644760851983985 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 992.0 urls with 731.0 successes\n",
            "73.68951612903226% success rate for all urls \n",
            "0.036447693319881666 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 1242.0 urls with 904.0 successes\n",
            "72.78582930756843% success rate for is_flickr urls \n",
            "0.036605070122575335 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 1242.0 urls with 904.0 successes\n",
            "72.78582930756843% success rate for all urls \n",
            "0.0366051149579276 seconds spent per all succesful image download\n",
            "Scraping images for class \"fire\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 1492.0 urls with 1097.0 successes\n",
            "73.5254691689008% success rate for is_flickr urls \n",
            "0.03771952835124737 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 1492.0 urls with 1097.0 successes\n",
            "73.5254691689008% success rate for all urls \n",
            "0.037719609417911006 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 1742.0 urls with 1289.0 successes\n",
            "73.99540757749713% success rate for is_flickr urls \n",
            "0.036317213086586204 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 1742.0 urls with 1289.0 successes\n",
            "73.99540757749713% success rate for all urls \n",
            "0.036317279858585474 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 1992.0 urls with 1479.0 successes\n",
            "74.24698795180723% success rate for is_flickr urls \n",
            "0.03706267881103268 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 1992.0 urls with 1479.0 successes\n",
            "74.24698795180723% success rate for all urls \n",
            "0.03706271395318971 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 2242.0 urls with 1676.0 successes\n",
            "74.75468331846565% success rate for is_flickr urls \n",
            "0.037219827101168036 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 2242.0 urls with 1676.0 successes\n",
            "74.75468331846565% success rate for all urls \n",
            "0.0372198808733774 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 2492.0 urls with 1877.0 successes\n",
            "75.32102728731942% success rate for is_flickr urls \n",
            "0.03579277895712509 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 2492.0 urls with 1877.0 successes\n",
            "75.32102728731942% success rate for all urls \n",
            "0.035792830400665075 seconds spent per all succesful image download\n",
            "Scraping images for class \"computer screen\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 2742.0 urls with 2077.0 successes\n",
            "75.74762946754194% success rate for is_flickr urls \n",
            "0.03555765528488343 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 2742.0 urls with 2077.0 successes\n",
            "75.74762946754194% success rate for all urls \n",
            "0.03555768868873828 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 2992.0 urls with 2265.0 successes\n",
            "75.70187165775401% success rate for is_flickr urls \n",
            "0.03436058372851239 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 2992.0 urls with 2265.0 successes\n",
            "75.70187165775401% success rate for all urls \n",
            "0.034360630359607555 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 3242.0 urls with 2460.0 successes\n",
            "75.87908698334361% success rate for is_flickr urls \n",
            "0.03307560963359305 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 3242.0 urls with 2460.0 successes\n",
            "75.87908698334361% success rate for all urls \n",
            "0.0330756493700229 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 3497.0 urls with 2657.0 successes\n",
            "75.97941092364884% success rate for is_flickr urls \n",
            "0.03244719489158254 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 3497.0 urls with 2657.0 successes\n",
            "75.97941092364884% success rate for all urls \n",
            "0.032447212568835114 seconds spent per all succesful image download\n",
            "Scraping images for class \"car\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 3742.0 urls with 2865.0 successes\n",
            "76.56333511491181% success rate for is_flickr urls \n",
            "0.03263464756244972 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 3742.0 urls with 2865.0 successes\n",
            "76.56333511491181% success rate for all urls \n",
            "0.03263466270806278 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 3992.0 urls with 3072.0 successes\n",
            "76.95390781563127% success rate for is_flickr urls \n",
            "0.032204060427223645 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 3992.0 urls with 3072.0 successes\n",
            "76.95390781563127% success rate for all urls \n",
            "0.03220408409833909 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 4242.0 urls with 3282.0 successes\n",
            "77.36916548797737% success rate for is_flickr urls \n",
            "0.03214301734636064 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 4242.0 urls with 3282.0 successes\n",
            "77.36916548797737% success rate for all urls \n",
            "0.032143046694656174 seconds spent per all succesful image download\n",
            "Scraping images for class \"fight\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 4492.0 urls with 3486.0 successes\n",
            "77.60463045414069% success rate for is_flickr urls \n",
            "0.03355688475632353 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 4492.0 urls with 3486.0 successes\n",
            "77.60463045414069% success rate for all urls \n",
            "0.03355691471253055 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 4742.0 urls with 3682.0 successes\n",
            "77.64656263180093% success rate for is_flickr urls \n",
            "0.03331692532182452 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 4742.0 urls with 3682.0 successes\n",
            "77.64656263180093% success rate for all urls \n",
            "0.0333169420279607 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 4992.0 urls with 3889.0 successes\n",
            "77.90464743589743% success rate for is_flickr urls \n",
            "0.033376982414989126 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 4992.0 urls with 3889.0 successes\n",
            "77.90464743589743% success rate for all urls \n",
            "0.03337700423988348 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 5242.0 urls with 4093.0 successes\n",
            "78.08088515833651% success rate for is_flickr urls \n",
            "0.033316320467775794 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 5242.0 urls with 4093.0 successes\n",
            "78.08088515833651% success rate for all urls \n",
            "0.03331634732117549 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 5494.0 urls with 4279.0 successes\n",
            "77.88496541681835% success rate for is_flickr urls \n",
            "0.03351053257750752 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 5494.0 urls with 4279.0 successes\n",
            "77.88496541681835% success rate for all urls \n",
            "0.033510544501222386 seconds spent per all succesful image download\n",
            "Scraping images for class \"baseball bat\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 5742.0 urls with 4481.0 successes\n",
            "78.03901079763149% success rate for is_flickr urls \n",
            "0.03439715732769412 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 5742.0 urls with 4481.0 successes\n",
            "78.03901079763149% success rate for all urls \n",
            "0.03439716828824473 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 5992.0 urls with 4707.0 successes\n",
            "78.5547396528705% success rate for is_flickr urls \n",
            "0.033661555301770806 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 5992.0 urls with 4707.0 successes\n",
            "78.5547396528705% success rate for all urls \n",
            "0.03366157009213093 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 6242.0 urls with 4915.0 successes\n",
            "78.7407882089074% success rate for is_flickr urls \n",
            "0.03285736513768426 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 6242.0 urls with 4915.0 successes\n",
            "78.7407882089074% success rate for all urls \n",
            "0.032857390022471865 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 6496.0 urls with 5127.0 successes\n",
            "78.92549261083744% success rate for is_flickr urls \n",
            "0.03208733349021285 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 6496.0 urls with 5127.0 successes\n",
            "78.92549261083744% success rate for all urls \n",
            "0.03208734595289653 seconds spent per all succesful image download\n",
            "Scraping images for class \"cupboard\"\n",
            "Multiprocessing workers: 8\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 6742.0 urls with 5320.0 successes\n",
            "78.90833580539899% success rate for is_flickr urls \n",
            "0.031920652550862245 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 6742.0 urls with 5320.0 successes\n",
            "78.90833580539899% success rate for all urls \n",
            "0.03192066595070344 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 6992.0 urls with 5516.0 successes\n",
            "78.89016018306636% success rate for is_flickr urls \n",
            "0.03132278185291858 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 6992.0 urls with 5516.0 successes\n",
            "78.89016018306636% success rate for all urls \n",
            "0.031322795857200596 seconds spent per all succesful image download\n",
            "\n",
            "Scraping stats:\n",
            "STATS For class is_flickr:\n",
            " tried 7242.0 urls with 5712.0 successes\n",
            "78.87323943661971% success rate for is_flickr urls \n",
            "0.030744811566937872 seconds spent per is_flickr succesful image download\n",
            "STATS For class not_flickr:\n",
            " tried 0.0 urls with 0.0 successes\n",
            "STATS For class all:\n",
            " tried 7242.0 urls with 5712.0 successes\n",
            "78.87323943661971% success rate for all urls \n",
            "0.03074482809595701 seconds spent per all succesful image download\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTt3IU9RC8nB",
        "colab_type": "code",
        "outputId": "d7767f19-2f4a-4b68-fdee-1ce73e1c6658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "import gc\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnJIHJNr2QJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = './images/imagenet_images'\n",
        "CATAGORIES = ['people', 'fire', 'computer screen', 'car', 'fight', 'baseball bat', 'cupboard']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q1cJfTvGkqW",
        "colab_type": "code",
        "outputId": "9a87c0e6-a17e-4d87-f146-5a32c190ba65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  count = 0\n",
        "  for category in CATAGORIES:\n",
        "    count = 0\n",
        "    print('')\n",
        "    print(category)\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    class_num = CATAGORIES.index(category)\n",
        "      \n",
        "    for img in os.listdir(path):\n",
        "      try:\n",
        "        img_array = cv2.imread(os.path.join(path, img))\n",
        "        new_array = cv2.resize(img_array, (299, 299))\n",
        "        training_data.append([new_array, class_num])\n",
        "        count = count + 1\n",
        "      except Exception as e:\n",
        "        pass\n",
        "    print(count, end=' ')\n",
        "\n",
        "create_training_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "people\n",
            "1003 \n",
            "fire\n",
            "1005 \n",
            "computer screen\n",
            "660 \n",
            "car\n",
            "727 \n",
            "fight\n",
            "923 \n",
            "baseball bat\n",
            "838 \n",
            "cupboard\n",
            "661 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCxokl6cFbRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4CCX_WsKvae",
        "colab_type": "code",
        "outputId": "6f369a23-38e6-4080-e173-89384714bc6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "leng = (len(training_data) * 80) // 100\n",
        "print(leng)\n",
        "\n",
        "\n",
        "for features, label in training_data[:leng]:\n",
        "  X_train.append(features)\n",
        "  y_train.append(label)\n",
        "for features, label in training_data[leng:]:\n",
        "  X_test.append(features)\n",
        "  y_test.append(label)\n",
        "\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4653\n",
            "(4653, 299, 299, 3)\n",
            "(1164, 299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qtJT87K1Xtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open('./drive/My Drive/Images2.pickle', 'wb')\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('./drive/My Drive/label2.pickle', 'wb')\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# pickle_out = open('Images.pickle', 'wb')\n",
        "# pickle.dump(X, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open('label.pickle', 'wb')\n",
        "# pickle.dump(y, pickle_out)\n",
        "# pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ65JbfRSKBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open('./drive/My Drive/ImagesTrain.pickle', 'wb')\n",
        "pickle.dump(X_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('./drive/My Drive/labelTrain.pickle', 'wb')\n",
        "pickle.dump(y_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('./drive/My Drive/ImagesTest.pickle', 'wb')\n",
        "pickle.dump(X_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('./drive/My Drive/labelTest.pickle', 'wb')\n",
        "pickle.dump(y_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# pickle_out = open('ImagesTrain.pickle', 'wb')\n",
        "# pickle.dump(X_train, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open('labelTrain.pickle', 'wb')\n",
        "# pickle.dump(y_train, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open('ImagesTest.pickle', 'wb')\n",
        "# pickle.dump(X_test, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open('labelTest.pickle', 'wb')\n",
        "# pickle.dump(y_test, pickle_out)\n",
        "# pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5cCL4zY1ys9",
        "colab_type": "code",
        "outputId": "f2c707ff-2866-4e7a-ad16-cb70946b6ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = pickle.load(open(\"./drive/My Drive/Images2.pickle\", 'rb'))\n",
        "y = pickle.load(open(\"./drive/My Drive/label2.pickle\", 'rb'))\n",
        "\n",
        "# X = pickle.load(open(\"Images.pickle\", 'rb'))\n",
        "# y = pickle.load(open(\"label.pickle\", 'rb'))\n",
        "\n",
        "X = X/255.0\n",
        "# print(y[:10])\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "# X = []\n",
        "# y = []\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD2gy9bCSd9I",
        "colab_type": "code",
        "outputId": "e7f055e7-97c6-4f76-f23e-e838af8c5c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = pickle.load(open(\"./drive/My Drive/ImagesTrain.pickle\", 'rb'))\n",
        "y_train = pickle.load(open(\"./drive/My Drive/labelTrain.pickle\", 'rb'))\n",
        "X_test = pickle.load(open(\"./drive/My Drive/ImagesTest.pickle\", 'rb'))\n",
        "y_test = pickle.load(open(\"./drive/My Drive/labelTest.pickle\", 'rb'))\n",
        "\n",
        "# X = pickle.load(open(\"Images.pickle\", 'rb'))\n",
        "# y = pickle.load(open(\"label.pickle\", 'rb'))\n",
        "\n",
        "# X_train = pickle.load(open(\"ImagesTrain.pickle\", 'rb'))\n",
        "# y_train = pickle.load(open(\"labelTrain.pickle\", 'rb'))\n",
        "# X_test = pickle.load(open(\"ImagesTest.pickle\", 'rb'))\n",
        "# y_test = pickle.load(open(\"labelTest.pickle\", 'rb'))\n",
        "\n",
        "\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "# print(y[:10])\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "# X = []\n",
        "# y = []\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6B8dXlwrb4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(y_test[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYb1_HKlD5en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.layers import Input,  Dense, Dropout, Flatten, Reshape, concatenate, BatchNormalization, Activation, Add, Lambda\n",
        "from keras.layers.convolutional import (Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D)\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.utils.io_utils import HDF5Matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp5SpRi0QXAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Inception(x, filters, name):\n",
        "\n",
        "    f1, f2, f3 = filters\n",
        "\n",
        "    layer_1 = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu',name=name+'_a')(x)\n",
        "\n",
        "    layer_2 = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu',name=name+'_1b')(x)\n",
        "    layer_2 = Conv2D(f2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',name=name+'_b')(layer_2)\n",
        "\n",
        "    layer_3 = Conv2D(f3, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu',name=name+'_1c')(x)\n",
        "    layer_3 = Conv2D(f3, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu',name=name+'_c')(layer_3)\n",
        "\n",
        "    layer_4 = MaxPooling2D(pool_size=(3,3), strides=(1, 1), padding='same')(x)\n",
        "    layer_4 = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu', name=name+'_d')(layer_4)\n",
        "\n",
        "    ouput = concatenate([layer_1, layer_2, layer_3, layer_4], name=name+'_final')\n",
        "\n",
        "    return ouput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ln3qqhyWnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  input_shape = (299, 299, 3)\n",
        "\n",
        "  main_input = Input(shape=input_shape, dtype='float32', name='main_input')\n",
        "\n",
        "  x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', name='conv1')(main_input)\n",
        "  x = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='valid', name='pool1')(x)\n",
        "\n",
        "  x = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu', name='conv2a')(x)\n",
        "  x = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu', name='conv2b')(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='valid', name='pool2')(x)\n",
        "\n",
        "  x = Inception(x, [8, 16, 32], '3_a_Incept')\n",
        "  # x = Inception(x, [8, 16, 32], '3_b_Incept')\n",
        "  x = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='valid', name='pool3')(x)\n",
        "\n",
        "  x = Inception(x, [16, 32, 64], '4_a_Incept')\n",
        "  x = Inception(x, [16, 32, 64], '4_b_Incept')\n",
        "  # x = Inception(x, [16, 32, 64], '4_c_Incept')\n",
        "  # x = Inception(x, [32, 64, 128], '4_d_Incept')\n",
        "  x = Inception(x, [32, 64, 128], '4_e_Incept')\n",
        "  x = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='valid', name='pool4')(x)\n",
        "\n",
        "  x = Inception(x, [64, 128, 256], '5_a_Incept')\n",
        "  # x = Inception(x, [64, 128, 256], '5_b_Incept')\n",
        "  x = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='valid', name='pool5')(x)\n",
        "\n",
        "  x = Flatten(name='output')(x)\n",
        "\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  output = Dense(8, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=main_input, outputs=output)\n",
        "\n",
        "  checkpoint = ModelCheckpoint(filepath='models\\\\checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
        "\n",
        "  callback_list = [checkpoint]\n",
        "\n",
        "  # metrics = ['accuracy', 'top_k_categorical_accuracy']\n",
        "  optimizer = Adam(lr=1e-5, decay=1e-6)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1V7PTktza5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \n",
        "    \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    F1, F2 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    X = Conv2D(filters = F2, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Yoj5YZt7hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    F1, F2 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(F2, (1, 1), strides = (1, 1), name = conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(F2, (1, 1), strides = (s, s), name = conv_name_base + '1')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q32B-x6huIqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape = (299, 299, 3), classes = 7):    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 128], stage=2, block='b')\n",
        "    # X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 256], stage=3, block='b')\n",
        "    # X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    # X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 512], stage=4, block='b')\n",
        "    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # X = convolutional_block(X, f = 3, filters = [512, 1024], stage = 5, block='a', s = 2)\n",
        "    # X = identity_block(X, 3, [512, 1024], stage=5, block='b')\n",
        "    # X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D((2, 2), name = 'avg_pool')(X)\n",
        "    \n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
        "\n",
        "    rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_delta=1e-7)\n",
        "    callbacks = [rlrp]\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "    optimizer = Adam(lr=1e-4, decay=1e-6)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_KYIyYF2d8",
        "colab_type": "code",
        "outputId": "ea0bc4c2-51c8-4dd4-8d7f-609ff072005d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model= model(input_shape = (299, 299, 3), classes = 7)\n",
        "model.summary()\n",
        "# model = model()\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 305, 305, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 150, 150, 64) 9472        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 150, 150, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 150, 150, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 74, 74, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 74, 74, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 74, 74, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 74, 74, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 74, 74, 128)  8320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 74, 74, 128)  8320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 74, 74, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 74, 74, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 74, 74, 64)   8256        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 74, 74, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 74, 74, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 74, 74, 128)  8320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 74, 74, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 74, 74, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 74, 74, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 36, 36, 128)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 18, 18, 128)  16512       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 18, 18, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 18, 18, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 18, 18, 256)  33024       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 18, 18, 256)  33024       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 18, 18, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 18, 18, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 18, 18, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 18, 18, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 18, 18, 128)  32896       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 18, 18, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 18, 18, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 18, 18, 256)  33024       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 18, 18, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 18, 18, 256)  0           activation_7[0][0]               \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 18, 18, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)    0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    65792       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 4, 4, 512)    131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 4, 4, 512)    131584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           activation_11[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 2, 2, 512)    0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 816,135\n",
            "Trainable params: 808,839\n",
            "Non-trainable params: 7,296\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY1vtiGgGbs2",
        "colab_type": "code",
        "outputId": "4149d848-beb8-46a0-abbe-1ef42dfef32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=150, epochs=25)\n",
        "# model.fit(X, y, validation_split=0.2, batch_size=100, epochs=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4653 samples, validate on 1164 samples\n",
            "Epoch 1/25\n",
            "4653/4653 [==============================] - 26s 6ms/step - loss: 1.6321 - acc: 0.4120 - val_loss: 1.5234 - val_acc: 0.4656\n",
            "Epoch 2/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 1.0947 - acc: 0.6089 - val_loss: 1.2035 - val_acc: 0.5541\n",
            "Epoch 3/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.9371 - acc: 0.6763 - val_loss: 1.1379 - val_acc: 0.5902\n",
            "Epoch 4/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.8353 - acc: 0.7264 - val_loss: 1.1063 - val_acc: 0.5936\n",
            "Epoch 5/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.7511 - acc: 0.7554 - val_loss: 1.0876 - val_acc: 0.6100\n",
            "Epoch 6/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.6653 - acc: 0.7907 - val_loss: 0.9830 - val_acc: 0.6555\n",
            "Epoch 7/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.6355 - acc: 0.7924 - val_loss: 1.0186 - val_acc: 0.6375\n",
            "Epoch 8/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.5672 - acc: 0.8279 - val_loss: 0.9531 - val_acc: 0.6658\n",
            "Epoch 9/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.5263 - acc: 0.8425 - val_loss: 0.9536 - val_acc: 0.6735\n",
            "Epoch 10/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.4775 - acc: 0.8637 - val_loss: 0.8918 - val_acc: 0.6942\n",
            "Epoch 11/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.4469 - acc: 0.8736 - val_loss: 0.9438 - val_acc: 0.6830\n",
            "Epoch 12/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.4649 - acc: 0.8652 - val_loss: 0.9560 - val_acc: 0.6873\n",
            "Epoch 13/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.4565 - acc: 0.8601 - val_loss: 0.9791 - val_acc: 0.6546\n",
            "Epoch 14/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.4036 - acc: 0.8857 - val_loss: 0.8998 - val_acc: 0.6881\n",
            "Epoch 15/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.3733 - acc: 0.9054 - val_loss: 0.8885 - val_acc: 0.6873\n",
            "Epoch 16/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.3304 - acc: 0.9173 - val_loss: 0.8373 - val_acc: 0.6976\n",
            "Epoch 17/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2690 - acc: 0.9476 - val_loss: 0.8662 - val_acc: 0.6950\n",
            "Epoch 18/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2874 - acc: 0.9342 - val_loss: 0.8390 - val_acc: 0.7088\n",
            "Epoch 19/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2344 - acc: 0.9557 - val_loss: 0.8739 - val_acc: 0.6950\n",
            "Epoch 20/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2648 - acc: 0.9415 - val_loss: 0.9131 - val_acc: 0.6916\n",
            "Epoch 21/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2800 - acc: 0.9323 - val_loss: 0.9141 - val_acc: 0.6838\n",
            "Epoch 22/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.1973 - acc: 0.9652 - val_loss: 0.9045 - val_acc: 0.6967\n",
            "Epoch 23/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2343 - acc: 0.9458 - val_loss: 0.8918 - val_acc: 0.6950\n",
            "Epoch 24/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2353 - acc: 0.9497 - val_loss: 0.9026 - val_acc: 0.7053\n",
            "Epoch 25/25\n",
            "4653/4653 [==============================] - 16s 3ms/step - loss: 0.2341 - acc: 0.9450 - val_loss: 0.8884 - val_acc: 0.7045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c100a16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQQ0YahNK2lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./drive/My Drive/imageclassifier2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXmggQ0YSp_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape = (299, 299, 3), classes = 8):\n",
        "       \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 256], stage=2, block='b')\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 512], stage=3, block='b')\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 1024], stage=4, block='b')\n",
        "\n",
        "    # X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    # X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "\n",
        "    X = AveragePooling2D((2, 2), name = 'avg_pool')(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "    optimizer = Adam(lr=1e-4, decay=1e-6)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdioG4bjq-0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}